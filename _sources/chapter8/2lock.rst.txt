互斥锁
===============================================

本节导读
-----------------------------------------------

引子：多线程计数器
-----------------------------------------------

我们知道，同进程下的线程共享进程的地址空间，因此它们均可以读写程序内的全局/静态数据。通过这种方式，线程可以非常方便的相互协作完成一项任务。下面是一个简单的例子，同学可以在 Linux/Windows 等系统上运行这段代码：

.. code-block:: rust
    :linenos:

    // adder.rs

    static mut A: usize = 0;
    const THREAD_COUNT: usize = 4;
    const PER_THREAD: usize = 10000;
    fn main() {
        let mut v = Vec::new();
        for _ in 0..THREAD_COUNT {
            v.push(std::thread::spawn(|| {
                unsafe {
                    for _ in 0..PER_THREAD {
                        A = A + 1;
                    }
                }
            }));
        }
        for handle in v {
            handle.join().unwrap();
        }
        println!("{}", unsafe { A });
    }

前一节中我们已经熟悉了多线程应用的编程方法。因此我们很容易看出这个程序开了 ``THREAD_COUNT`` 个线程，每个线程都将一个全局变量 ``A`` 加 1 ，次数为 ``PER_THREAD`` 次。从中可以看出多线程协作确实比较方便，因为我们只需将单线程上的代码（即第 11~13 行的主循环）提交给多个线程就从单线程得到了多线程版本。然而，这样确实能够达到我们预期的效果吗？

全局变量 ``A`` 的初始值为 ``0`` ，而 ``THREAD_COUNT`` 个线程每个将其加 1 重复 ``PER_THREAD`` 次，因此当所有的线程均完成任务之后，我们预期 ``A`` 的值应该是二者的乘积即 40000 。让我们尝试运行一下这个程序，可以看到类似下面的结果：

.. code-block:: console

    $ rustc adder.rs
    $ ./adder
    40000
    $ ./adder
    17444
    $ ./adder
    36364
    $ ./adder
    39552
    $ ./adder
    21397

可以看到只有其中一次的结果是正确的，其他的情况下结果都比较小且各不相同，这是为什么呢？我们可以尝试分析一下哪些因素会影响到代码的执行结果，使得结果与我们的预期不同。

1. 编译器在将源代码编译为汇编代码或者机器码的时候会进行一些优化。
2. 操作系统在执行程序的时候会进行调度。
3. CPU 在执行指令的时候会进行一些调度或优化。

那么按照顺序首先来检查第一步，即编译器生成的汇编代码是否正确。可以用如下命令反汇编可执行文件 ``adder`` 生成汇编代码 ``adder.asm`` ：

.. code-block:: console

    $ rustup component add llvm-tools-preview
    $ rust-objdump -D adder > adder.asm

在 ``adder.asm`` 中找到传给每个线程的闭包函数（这部分是我们自己写的，更容易出错）的汇编代码：

.. code-block::
    :linenos:

    # adder.asm
    000000000000bce0 <_ZN5adder4main28_$u7b$$u7b$closure$u7d$$u7d$17hfcc06370a766a1c4E>:
        bce0: subq    $56, %rsp
        bce4: movq    $0, 8(%rsp)
        bced: movq    $10000, 16(%rsp)        # imm = 0x2710
        bcf6: movq    8(%rsp), %rdi
        bcfb: movq    16(%rsp), %rsi
        bd00: callq   0xb570 <_ZN63_$LT$I$u20$as$u20$core..iter..traits..collect..IntoIterator$GT$9into_iter17h0e9595229a318c79E>
        bd05: movq    %rax, 24(%rsp)
        bd0a: movq    %rdx, 32(%rsp)
        bd0f: leaq    24(%rsp), %rdi
        bd14: callq   0xb560 <_ZN4core4iter5range101_$LT$impl$u20$core..iter..traits..iterator..Iterator$u20$for$u20$core..ops..range..Range$LT$A$GT$$GT$4next17h703752eeba5b7a01E>
        bd19: movq    %rdx, 48(%rsp)
        bd1e: movq    %rax, 40(%rsp)
        bd23: cmpq    $0, 40(%rsp)
        bd29: jne     0xbd30 <_ZN5adder4main28_$u7b$$u7b$closure$u7d$$u7d$17hfcc06370a766a1c4E+0x50>
        bd2b: addq    $56, %rsp
        bd2f: retq
        bd30: movq    328457(%rip), %rax      # 0x5c040 <_ZN5adder1A17hce2f3c024bd1f707E>
        bd37: addq    $1, %rax
        bd3b: movq    %rax, (%rsp)
        bd3f: setb    %al
        bd42: testb   $1, %al
        bd44: jne     0xbd53 <_ZN5adder4main28_$u7b$$u7b$closure$u7d$$u7d$17hfcc06370a766a1c4E+0x73>
        bd46: movq    (%rsp), %rax
        bd4a: movq    %rax, 328431(%rip)      # 0x5c040 <_ZN5adder1A17hce2f3c024bd1f707E>
        bd51: jmp     0xbd0f <_ZN5adder4main28_$u7b$$u7b$closure$u7d$$u7d$17hfcc06370a766a1c4E+0x2f>
        bd53: leaq    242854(%rip), %rdi      # 0x47200 <str.0>
        bd5a: leaq    315511(%rip), %rdx      # 0x58dd8 <writev@GLIBC_2.2.5+0x58dd8>
        bd61: leaq    -15080(%rip), %rax      # 0x8280 <_ZN4core9panicking5panic17h73f802489c27713bE>
        bd68: movl    $28, %esi
        bd6d: callq   *%rax
        bd6f: ud2
        bd71: nopw    %cs:(%rax,%rax)
        bd7b: nopl    (%rax,%rax)

虽然函数名经过了一些混淆，还是能看出这是程序 ``adder`` 的 ``main`` 函数中的一个闭包（Closure）。我们现在基于 x86_64 而不是 RISC-V 架构，因此会有一些不同：

- 指令的目标寄存器后置而不是像 RISC-V 一样放在最前面；
- 使用 ``%rax,%rdx,%rsi,%rdi`` 作为 64 位通用寄存器，观察代码可以发现 ``%rsi`` 和 ``%rdi`` 用来传参， ``%rax`` 和 ``%rdx`` 用来保存返回值；
- ``%rsp`` 是 64 位栈指针，功能与 RISC-V 中的 ``sp`` 相同；
- ``%rip`` 是 64 位指令指针，指向当前指令的下一条指令的地址，等同于我们之前介绍的 PC 寄存器。
- ``callq`` 为函数调用， ``retq`` 则为函数返回。

在了解了这些知识之后，我们可以尝试读一读代码：

- 第 3 行是在分配栈帧；
- 第 4~8 行准备参数，并调用标准库实现的 ``IntoIterator`` trait 的 ``into_iter`` 方法将 Range 0..10000 转化为一个迭代器；
- 第 9 行的 ``24(%rsp)`` 应该保存的是生成的迭代器的地址；
- 第 11 行开始进入主循环。第 11 行加载 ``24(%rsp)`` 到 ``%rdi`` 作为参数并在第 12 行调用 ``Iterator::next`` 函数，返回值在 ``%rdx`` 和 ``%rax`` 中并被保存在栈上。我们知道 ``Iterator::next`` 返回的是一个 ``Option<T>`` 。观察第 15-16 行，当 ``%rax`` 里面的值不为 0 的时候就跳转到 0xbd30 ，否则就向下执行到第 17-18 行回收栈帧并退出。这意味着 ``%rax`` 如果为 0 的话说明返回的是 ``None`` ，这时迭代器已经用尽，就可以退出函数了。于是，主循环的次数为 10000 次就定下来了。
- 0xbd30 （第 19 行）开始才真正进入 ``A=A+1`` 的部分。第 19 行从虚拟地址 0x5c040（这就是全局变量 ``A`` 的地址）加载一个 usize 到寄存器 ``%rax`` 中；第 20 行将 ``%rax`` 加一；第 26 行将寄存器 ``%rax`` 的值写回到虚拟地址 0x5c040 中。也就是说 ``A=A+1`` 是通过这三条指令达成。第 27 行无条件跳转到 0xbd0f 也就是第 11 行，进入下一轮循环。

.. note::

    **Rust Tips: Rust 的无符号溢出是不可恢复错误**

    有兴趣的同学可以读一读第 21~25 行代码，它可以判断在将 ``%rax`` 加一的时候是否出现溢出（注意其中复用了 ``%rax`` ，因此有一次额外的保存/恢复）。如果出现溢出的话则会跳转到 0xbd53（第 28 行）直接 panic 。

    从中我们可以看出，相比 C/C++ 来说 Rust 的确会生成更多的代码来针对算术溢出、数组越界的情况进行判断，但是这并不意味着在现代 CPU 上就会有很大的性能损失。如果可以确保不会出现溢出的情况，可以考虑使用 unsafe 的 ``usize::unchecked_add`` 来避免生成相关的判断代码并提高性能。

我们可以得出结论：编译器生成的汇编代码是符合我们的预期的。那么接下来进行第二步，操作系统的调度是否会影响结果的正确性呢？在具体分析之前，我们先对汇编代码进行简化，只保留直接与结果相关的部分。那么，可以看成每个线程进行 ``PER_THREAD`` 次操作，每次操作按顺序进行下面三个步骤：

1. 使用访存指令，从全局变量 ``A`` 的地址 addr 加载 ``A`` 当前的值到寄存器 reg；
2. 使用算术指令将寄存器 reg 的值加一；
3. 使用访存指令，将 reg 的值写回到全局变量 ``A`` 的地址 addr，至此 ``A`` 的值成功加一。

这是一个可以认为与具体指令集架构无关的过程。因为对于传统的计算机架构而言，在 ALU 上进行的算术指令需要以寄存器为载体，而不能直接在 RAM 上进行操作。在此基础上，我们可以建立简化版的线程执行模型，如下图所示：

.. image:: adder-example-1.png
    :align: center
    :width: 300px

.. _term-interleave:

目前有两个线程 T0 和 T1 ，二者都是从上到下顺序执行。我们将 ``A=A+1`` 的操作打包成包含三条指令的一个块，剩下的绿色区域则表示与操作无关的那些指令。每个线程都会有一种幻觉就是它能够从头到尾独占 CPU 执行，但实际上操作系统会通过抢占式调度划分时间片使它们 **交错** (Interleave) 运行。注意时钟中断可能在执行任意一条指令之后触发，因此时间片之间的边界可能是任意一条指令。下图是一种可能的时间片划分方式：

.. image:: adder-example-2.png
    :align: center
    :width: 600px

我们暂时只考虑单 CPU 的简单情况。按照时间顺序，CPU 依次执行 T0 的时间片 0、T1 的时间片 1、T0 的时间片 2 和 T1 的时间片 3，在相邻两个时间片之间会进行一次线程切换。注意到在这种划分方式中，两个线程各有一个操作块被划分到多个时间片完成。图片的右侧展示了 CPU 视角的指令执行过程，我们仅关注操作块中的指令，并尝试模拟一下：

.. list-table:: 
    :widths: 40 30 50 50
    :header-rows: 1

    * - 动作
      - 所属线程
      - 寄存器 reg 的值（动作后）
      - addr 处的值（动作后）
    * - 切换到 T0
      - T0
      - -
      - v
    * - LOAD reg, addr
      - T0
      - v
      - v
    * - ADD reg, 1
      - T0
      - v+1
      - v
    * - T0 切换到 T1
      - T1
      - -
      - v
    * - LOAD reg, addr
      - T1
      - v
      - v
    * - ADD reg, 1
      - T1
      - v+1
      - v
    * - T1 切换到 T0
      - T0
      - v+1
      - v
    * - STORE reg, addr
      - T0
      - v+1
      - v+1
    * - T0 切换到 T1
      - T1
      - v+1
      - v+1
    * - STORE reg, addr
      - T1
      - v+1
      - v+1
    * - T1 切换出去
      - -
      - -
      - v+1

假设开始之前全局变量 ``A`` 的值为 v ，而在这来自两个线程的四个时间片中包含了完整的两个 ``A=A+1`` 的操作块，那么结束之后 ``A`` 的值应该变成 v+2 。然而我们模拟下来的结果却是 v+1 ，这是为什么呢？首先需要说明的是，尽管两个线程都使用寄存器 reg 中转，但是它们之间并不会产生冲突，因为在线程切换的时候会对线程上下文进行保存与恢复，其中也包括寄存器 reg 。因此我们可以认为两个线程均有一份自己独占的寄存器。言归正传，我们从结果入手进行分析， ``A`` 最终的值来源于我们在这段时间对它进行的最后一次写入，这次写入由 T1 进行，但是为什么 T1 会写入 v+1 而不是 v+2 呢？从 T1 的视角来看，首先要读取 ``A`` 的值到 reg ，发现是 v ，这一点就很奇怪，好像此前 T0 什么都没做一样。而后 T1 将 reg 的值加一变成 v+1 ，于是最后写入的也是这个值。所以，问题的关键在于 T0 将自己的 reg 更新为 v+1 之后，还没来得及写回到 ``A`` ，就被操作系统切换到 T1 ，因此 T1 会看到 v 而不是 v+1 。等再切换回 T0 将 v+1 写入到 ``A`` 的时候已经为时已晚，因为已经过了关键的 T1 读取 ``A`` 的时间点了，于是这次写入无法对 T1 产生任何影响，也无法影响到最终的结果了。因此，在这种情况下，由于操作系统的抢占式调度，可以看到 T0 的 ``A=A+1`` 操作完全在做无用功，于是最终结果比期望少 1 。

.. _term-indeterminate:
.. _term-race-condition:

从上个例子可以看出，操作系统的调度有可能使得两个线程上的操作块 **交错** 出现，也就是说两个操作块从开始到结束的时间区间存在交集。一旦出现这种情况，便会导致结果出现偏差。最终的结果取决于这种交错的情况出现多少次，如果完全没有出现则结果正确；否则出现次数越多，结果偏差越大。这就能够解释为什么我们每次运行 ``adder.rs`` 会得到不同的结果。这种运行结果 **不确定** (Indeterminate)，且取决于像是操作系统的调度顺序这种无法控制的外部事件的情况被称为 **竞态条件** (Race Condition) 。在 ``adder.rs`` 中，竞态条件导致了我们预料之外的结果，因此它应当被认为是一个 bug 。

我们尝试更加形象的说明为什么操作块交错出现就会有问题。在写程序的时候，我们需要做的是通过软件控制一些资源，这些资源可能是软件资源或者硬件资源。软件资源可能包括保存在内存中的一些数据结构，硬件资源可能是内存的一部分或者某些 I/O 设备。在资源被初始化之后，资源处于一种合法（Valid）状态，这里的合法状态是指资源符合一些特定的约束条件从而具有该种资源所应该具有的特征。以我们耳熟能详的链表数据结构为例，一个合法的链表应该满足每个节点的 next 指针均为空指针或者指向合法的内存区域。同时，next 指针不能形成环。当然，实际上还有更多的约束条件，我们使用自然语言很难完全表述它们。总之，只有满足所有的约束条件，我们才说这是一个合法的链表。

.. _term-intermediate-state:

每种资源可能都有多种不同的控制方式，每种控制方式称为对这种资源的一种操作。比如说，如果将链表看成一种资源，那么链表的插入和删除就是两种对链表的操作。每一种操作仅在资源处于合法状态时才能进行，且在操作完成之后保证资源仍旧处于合法状态。设想我们要实现链表的插入操作，这必须在待操作的数据结构是一个合法的链表这一前提下才能进行，不然我们的操作将完全没有意义。我们还需要保证插入之后链表依然合法，才称得上是正确的实现。但是资源并非任意时刻均处于合法状态。因为一般来说操作都比较复杂，会分成多个阶段多条指令完成。通常，处于合法状态的资源在操作时会变成不合法的 **中间状态** (Intermediate State)，待操作结束之后再重回合法状态。以我们的多线程计数器 ``adder.rs`` 为例，状态转移过程如下：

.. image:: adder-state-machine.png
    :align: center
    :width: 400px

这里我们将全局变量 ``A`` 视为一种资源，操作 ``A=A+1`` 为一个三阶段操作。我们可以用有限状态自动机来描述资源 ``A`` 和操作 ``A=A+1`` ：状态机中一共有 3 种状态，一个合法状态和两个不合法的中间状态 0 和 1。对于每次操作，第一条指令 ``A`` 从合法状态转移到中间状态 0；第二条指令 ``A`` 从中间状态 0 转移到中间状态 1；第三条指令 ``A`` 从中间状态 1 转移回合法状态。将操作块交错的情况代入到状态机中，最开始切换到 T0 之前 ``A`` 处于合法状态，接下来切换到 T0 执行了第一、二条指令之后 ``A`` 转移到中间状态 1，而此时操作系统切换到 T1 ， T1 又开始执行第一条指令。问题来了：我们发现中间状态 1 并没有定义此时再执行第一条指令应该如何转移。如果去执行的话，就会产生未定义行为并可能永远无法使 ``A`` 回到合法状态。不过，由于 ``adder.rs`` 中 ``A`` 只是一个整数，我们会发现 ``A`` 仍能回到合法状态，只是结果不对。如果换成一种复杂的数据结构，就会产生极其微妙且难以调试的结果。

因此，假设多个线程在同段时间内均尝试操作同一种共享资源，当一个线程开始操作之后，资源就处于不合法的中间态。此时，为了正确性，此时其他线程不能开始操作资源，因为操作的前提是资源处于合法状态，否则会产生未定义行为。等到这次操作结束，资源重新回到合法状态之后，之前操作的线程或者其他线程才能开始下一次操作。让我们引入一些操作系统中的术语来重新回顾一下。

.. _term-shared-resources:
.. _term-critical-section:
.. _term-mutual-exclusion:

**共享资源** (Shared Resources) 是指多个线程均能够访问的资源。对于共享资源进行操作的那部分代码被称为 **临界区** (Critical Section)。在多线程并发访问某种共享资源的时候，为了正确性，必须要满足 **互斥** (Mutual Exclusion) 访问要求，即同一时间最多只能有一个线程在这种共享资源的临界区之内。这样才能保证当一个线程开始操作时，共享资源总是处于合法状态，这保证了操作是有意义的。如果能够做到互斥访问的话，我们 ``adder.rs`` 出现 bug 的根源————即对于 ``A`` 的操作可能交错出现的情况便能够被避免。

.. _term-mutex:
.. _term-lock:

从 ``adder.rs`` 中可以看出，如果任由操作系统进行时间片切分和线程调度而不加任何特殊处理，是很难满足互斥访问要求的。那么应该如何实现互斥访问呢？接下来，我们将会尝试构建一组称之为 **互斥锁** (Mutex，源于 **Mut** ual **Ex** clusion，简称为 **锁** Lock) 的通用互斥原语来对临界区进行保护，从而在一般意义上保证互斥访问要求。这将是本节接下来的主要内容。

.. _term-atomic-instruction:

如果仅仅考虑 ``adder.rs`` 的话，其实不借助锁机制也能够解决问题。这是因为其中的共享资源为一个 64 位无符号整型，是一个十分简单的类型。对于这种原生类型，现代指令集架构额外提供一组 **原子指令** (Atomic Instruction) ，在某些架构上只需一条原子指令就能完成包括访存、算术运算在内的一系列功能。这就是说 ``adder.rs`` 中的 ``A=A+1`` 操作其实只需一条原子指令就能完成。如果这样做的话，我们相当于 **将临界区缩小为一条原子指令** ，这已经是处理器执行指令和时间片切分的最小单位，因此我们不使用任何保护手段也能满足互斥要求。修改之后的代码如下：

.. code-block:: rust
    :linenos:

    // adder.rs

    use std::sync::atomic::{AtomicUsize, Ordering};
    static A: AtomicUsize = AtomicUsize::new(0);
    const THREAD_COUNT: usize = 4;
    const PER_THREAD: usize = 10000;
    fn main() {
        let mut v = Vec::new();
        for _ in 0..THREAD_COUNT {
            v.push(std::thread::spawn(|| {
                for _ in 0..PER_THREAD {
                    A.fetch_add(1, Ordering::Relaxed);
                }
            }));
        }
        for handle in v {
            handle.join().unwrap();
        }
        println!("{}", A.load(Ordering::Relaxed));
    }

.. _term-atomicity:

Rust 核心库在 ``core::sync::atomic`` 中提供了很多原子类型，比如我们这里可以使用 ``usize`` 对应的原子类型 ``AtomicUsize`` ，它支持很多原子操作。比如，第 12 行 ``fetch_add`` 的功能是将 ``A`` 的值加一并返回 ``A`` 之前的值，这其中涉及到读取内存、算术运算和写回内存，但是却只需要这一个操作就能同时完成。这种原子操作基于硬件提供的原子指令，硬件可以保证其 **原子性** (Atomicity)，含义是该操作的一系列功能要么全部完成，要么都不完成，而不会出现有些完成有些未完成的情况。原子性中的“原子”是为了强调操作中的各种功能成为一个整体不可分割的属性。这种由硬件提供的 **原子指令是整个计算机系统中最根本的原子性和互斥性的来源** 。无论软件执行了哪些指令，也无论 CPU 执行指令的时候出现了哪些中断/异常，又或者多个 CPU 同时访问内存中同一个位置这种情形，都不能破坏原子指令的原子性。

可惜的是，原子指令虽然强大，其应用范围却比较有限，通常它只能用来保护 **单内存位置** 上的简单操作，比如 ``A=A+1`` 这种操作。当资源是比较复杂的数据结构的时候它就无能为力了。当然，我们也不会指望硬件提供一条“原子地完成红黑树插入/删除”这种指令，毕竟这样的数据结构有无数种，硬件总不可能对每种可能的数据结构和每种可能的操作都提供一条指令，这样的硬件是不存在的。即使如此我们也没有必要担心，只要我们能够灵活使用原子指令来根据实际需求限制多线程对共享资源的并发访问，比如基于原子指令实现通用的锁机制来保证互斥访问，所有的并发访问问题就一定能够迎刃而解。

.. 原子性相关 note
.. static mut 和 unsafe 的消失
.. 目前只是基于时钟中断抢占式调度的视角，但其实这个问题中的boss可能是内存不一致

.. 临界区(x)、不确定(x)、竞态条件(x)、原子性(x)、互斥(x)、共享资源(x)
.. 线程之间为什么会互相影响？
.. 因为我们访问共享资源的方式，是站在线程视角，假定线程在操作期间独占该资源。
.. 目前的情况是必须独占该资源吗？其实还涉及到逻辑划分和粒度的问题。
.. 但是实际上可以看到，由于操作系统的抢占式调度，这一点并不成立。如何不成立？
.. 在线程 T0 的操作未曾结束的时候，线程 T1 又开始操作。
.. 就如同同一个线程上一样，操作之间是需要相互隔离的，即不存在任何交集。
.. 线程因为共享资源的存在开始互相影响。线程通过共享资源互相协作。
.. 复杂共享资源的多阶段状态转移，中间状态下某些转移未定义，从而这就隐含了互斥。
.. 资源经过初始化之后，处于某种合法状态。一个操作是从合法状态到合法状态的转移。
